{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "XLearnLibraryNotFound",
     "evalue": "Cannot find xlearn Library in the candidate path",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXLearnLibraryNotFound\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32me:\\AI Project\\ETG Projects\\Rating SVD\\ffm.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/AI%20Project/ETG%20Projects/Rating%20SVD/ffm.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrecommenders\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython_splitters\u001b[39;00m \u001b[39mimport\u001b[39;00m python_stratified_split\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/AI%20Project/ETG%20Projects/Rating%20SVD/ffm.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrecommenders\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython_evaluation\u001b[39;00m \u001b[39mimport\u001b[39;00m map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/AI%20Project/ETG%20Projects/Rating%20SVD/ffm.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxlearn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxl\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI%20Project/ETG%20Projects/Rating%20SVD/ffm.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI%20Project/ETG%20Projects/Rating%20SVD/ffm.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32mc:\\Users\\hira\\.conda\\envs\\evnx\\lib\\site-packages\\xlearn\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mxlearn\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     20\u001b[0m VERSION_FILE \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(\u001b[39m__file__\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mVERSION\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(VERSION_FILE) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\hira\\.conda\\envs\\evnx\\lib\\site-packages\\xlearn\\xlearn.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mctypes\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m _LIB, XLearnHandle\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m _check_call, c_str\n\u001b[0;32m     22\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mXLearn\u001b[39;00m(\u001b[39mobject\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\hira\\.conda\\envs\\evnx\\lib\\site-packages\\xlearn\\base.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \t\u001b[39mreturn\u001b[39;00m lib\n\u001b[0;32m     33\u001b[0m \u001b[39m# load the xlearn library globally\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m _LIB \u001b[39m=\u001b[39m _load_lib()\n\u001b[0;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_call\u001b[39m(ret):\n\u001b[0;32m     37\u001b[0m \u001b[39m\t\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[39m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39m        return value from API calls\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39m\t\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hira\\.conda\\envs\\evnx\\lib\\site-packages\\xlearn\\base.py:27\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_lib\u001b[39m():\n\u001b[0;32m     26\u001b[0m \u001b[39m\t\u001b[39m\u001b[39m\"\"\"Load xlearn shared library\"\"\"\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \tlib_path \u001b[39m=\u001b[39m find_lib_path()\n\u001b[0;32m     28\u001b[0m \t\u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lib_path) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     29\u001b[0m \t\t\u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hira\\.conda\\envs\\evnx\\lib\\site-packages\\xlearn\\libpath.py:58\u001b[0m, in \u001b[0;36mfind_lib_path\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m# From github issues, most of installation errors come from machines w/o compilers\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m lib_path:\n\u001b[1;32m---> 58\u001b[0m     \u001b[39mraise\u001b[39;00m XLearnLibraryNotFound(\n\u001b[0;32m     59\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mCannot find xlearn Library in the candidate path\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     60\u001b[0m         )\n\u001b[0;32m     61\u001b[0m \u001b[39mreturn\u001b[39;00m lib_path\n",
      "\u001b[1;31mXLearnLibraryNotFound\u001b[0m: Cannot find xlearn Library in the candidate path"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from recommenders.utils.constants import SEED\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets.download_utils import maybe_download, unzip_file\n",
    "from recommenders.tuning.parameter_sweep import generate_param_grid\n",
    "from recommenders.datasets.pandas_df_utils import LibffmConverter\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "import xlearn as xl\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from csv file\n",
    "df1 = pd.read_csv('rats.csv')\n",
    "df2 = pd.read_csv('icat.csv')\n",
    "merged_df = pd.merge(df1, df2, on='itemId')\n",
    "\n",
    "# create new dataframe\n",
    "df3 = pd.DataFrame(merged_df)\n",
    "# df3['Category'] = df3['Category'].astype('category').cat.codes\n",
    "# Round the rating values to the nearest integer\n",
    "df3['rating'] = df3['rating'].round()\n",
    "\n",
    "# Convert the rating values to integer type\n",
    "df3['rating'] = df3['rating'].astype(int)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = LibffmConverter().fit(df3, col_rating='rating')\n",
    "df_out = converter.transform(df3)\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are in total {0} fields and {1} features.'.format(converter.field_count, converter.feature_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "LEARNING_RATE = 0.2\n",
    "LAMBDA = 0.002\n",
    "EPOCH = 10\n",
    "OPT_METHOD = \"sgd\" # options are \"sgd\", \"adagrad\" and \"ftrl\"\n",
    "\n",
    "# The metrics for binary classification options are \"acc\", \"prec\", \"f1\" and \"auc\"\n",
    "# for regression, options are \"rmse\", \"mae\", \"mape\"\n",
    "METRIC = \"auc\" \n",
    "# split header\n",
    "header = {\n",
    "    \"col_user\": \"userId\",\n",
    "    \"col_item\": \"itemId\",\n",
    "    \"col_rating\": \"rating\",\n",
    "    \"col_timestamp\": \"Category\",\n",
    "    \"col_prediction\": \"Prediction\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_stratified_split(df3, ratio=0.75, col_user=header[\"col_user\"], col_item=header[\"col_item\"], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training task\n",
    "ffm_model = xl.create_ffm()   # Use field-aware factorization machine (ffm)\n",
    "ffm_model.setTrain(train)     # Set the path of training dataset\n",
    "ffm_model.setValidate(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Convert the train and test dataframes to libffm format\n",
    "libffm_converter = LibffmConverter()\n",
    "train_libffm = libffm_converter.fit_transform(train_df)\n",
    "test_libffm = libffm_converter.transform(test_df)\n",
    "\n",
    "# Specify the FFM model parameters\n",
    "param_dict = {\n",
    "    \"lr\": [0.0001, 0.001, 0.01],\n",
    "    \"lambda\": [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Generate parameter grid for tuning\n",
    "params_list = generate_param_grid(param_dict)\n",
    "\n",
    "# Train and evaluate FFM models with different parameter settings\n",
    "best_score = 0.0\n",
    "best_model = None\n",
    "\n",
    "for params in params_list:\n",
    "    print(f'Training model with parameters: {params}')\n",
    "    timer = Timer()\n",
    "    \n",
    "    # Train the FFM model\n",
    "    # ffm_model = xl.FFMModel(task='binary', lr=LEARNING_RATE, lambda_=LAMBDA, epoch=EPOCH, opt=OPT_METHOD)\n",
    "    # ffm_model.fit(train_libffm, eval_set=(test_libffm, test_libffm))\n",
    "\n",
    "    # Train the FFM model\n",
    "    ffm_model = xl.create_ffm()\n",
    "    ffm_model.setTrain(train_libffm)\n",
    "    ffm_model.setValidate(test_libffm)\n",
    "    ffm_model.setTest(test_libffm)\n",
    "    ffm_model.fit(params)\n",
    "    \n",
    "    # Predict ratings on the test set\n",
    "    pred_scores = ffm_model.predict(test_libffm)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    map_score = map_at_k(test_df, pred_scores)\n",
    "    ndcg_score = ndcg_at_k(test_df, pred_scores)\n",
    "    precision_score = precision_at_k(test_df, pred_scores)\n",
    "    recall_score = recall_at_k(test_df, pred_scores)\n",
    "    rmse_score = mean_squared_error(test_df['Rating'], pred_scores) ** 0.5\n",
    "    mae_score = mean_absolute_error(test_df['Rating'], pred_scores)\n",
    "    \n",
    "    print(f'Evaluation results:')\n",
    "    print(f'MAP: {map_score}')\n",
    "    print(f'nDCG: {ndcg_score}')\n",
    "    print(f'Precision: {precision_score}')\n",
    "    print(f'Recall: {recall_score}')\n",
    "    print(f'RMSE: {rmse_score}')\n",
    "    print(f'MAE: {mae_score}')\n",
    "    \n",
    "    # Keep track of the best model based on MAP score\n",
    "    if map_score > best_score:\n",
    "        best_score = map_score\n",
    "        best_model = ffm_model\n",
    "    \n",
    "    print(f'Training time: {timer.elapsed_time()}')\n",
    "    print('--------------------------------------')\n",
    "\n",
    "print('Best model parameters:')\n",
    "print(best_model.get_model_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recomendENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
